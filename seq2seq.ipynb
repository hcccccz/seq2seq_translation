{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28485c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hc/anaconda3/envs/torch/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "import evaluate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc51b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "516d1624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 29000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1014\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"bentrevett/multi30k\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d1c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = (\n",
    "    dataset[\"train\"],\n",
    "    dataset[\"validation\"],\n",
    "    dataset[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09b54fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "de_nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3960679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(example, en_nlp, de_nlp, max_length, lower=True, sos_token=\"<sos>\", eos_token=\"<eos>\"):\n",
    "    en_tokens = [token.text for token in en_nlp(example['en'])][:max_length]\n",
    "    de_tokens = [token.text for token in de_nlp(example['de'])][:max_length]\n",
    "    if lower:\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "        de_tokens = [token.lower() for token in de_tokens]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    de_tokens = [sos_token] + de_tokens + [eos_token]\n",
    "    return {\"en_tokens\": en_tokens, \"de_tokens\": de_tokens}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb11cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1_000\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "min_freq = 2\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"en_nlp\": en_nlp,\n",
    "    \"de_nlp\": de_nlp,\n",
    "    \"max_length\": max_length,\n",
    "    \"lower\": lower,\n",
    "    \"sos_token\": sos_token,\n",
    "    \"eos_token\": eos_token,\n",
    "}\n",
    "\n",
    "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "652fa3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "specials = {pad_token: 0, unk_token: 1, sos_token: 2, eos_token: 3}\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, token_count, min_freq, specials: Dict[str, int]):\n",
    "        self.token2idx: Dict[str:int] = {}\n",
    "        for token, idx in specials.items():\n",
    "            self.token2idx[token] = idx\n",
    "\n",
    "        for token, cnt in token_count.items():\n",
    "            if cnt >= min_freq and token not in self.token2idx:\n",
    "\n",
    "                self.token2idx[token] = len(self.token2idx)\n",
    "\n",
    "        self.idx2token = {idx: token for token, idx in self.token2idx.items()}\n",
    "\n",
    "        self.token2idx = dict(sorted(self.token2idx.items(), key=lambda kv:kv[1]))\n",
    "        self.idx2token = dict(sorted(self.idx2token.items()))\n",
    "\n",
    "    @classmethod\n",
    "    def build_vocab_from_iterator(cls, iterator: List[List[str]], min_freq, specials: Dict[str, int]):\n",
    "        \"\"\"token_count: dict[str: int]\"\"\"\n",
    "        token_count = Counter([token for sentence in iterator for token in sentence ])\n",
    "        return cls(token_count, min_freq, specials)\n",
    "\n",
    "    def get_itos(self):\n",
    "        \"\"\"int to string\"\"\"\n",
    "        return list(self.token2idx.keys())\n",
    "\n",
    "    def get_stoi(self):\n",
    "        \"\"\"string to int\"\"\"\n",
    "        return self.token2idx\n",
    "\n",
    "    def lookup_indices(self, tokens):\n",
    "        return [self[token] for token in tokens]\n",
    "\n",
    "    def lookup_tokens(self, indices):\n",
    "        return [self.idx2token[index] for index in indices]\n",
    "\n",
    "    def __getitem__(self, token: str) -> int:\n",
    "        return self.token2idx.get(token, self.token2idx['<unk>'])\n",
    "\n",
    "    def __contains__(self, token: str) -> bool:\n",
    "        return token in self.token2idx\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.token2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed6fa8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab = Vocab.build_vocab_from_iterator(\n",
    "    train_data[\"en_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=specials,\n",
    ")\n",
    "\n",
    "de_vocab = Vocab.build_vocab_from_iterator(\n",
    "    train_data[\"de_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=specials,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9c42f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171, 4010, 225, 1, 1130]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i', 'love', 'watching', '<unk>', 'shows']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]\n",
    "\n",
    "indices = en_vocab.lookup_indices(tokens)\n",
    "print(indices)\n",
    "en_vocab.lookup_tokens(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f570e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def numericalize_example(example, en_vocab, de_vocab):\n",
    "    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n",
    "    de_ids = de_vocab.lookup_indices(example[\"de_tokens\"])\n",
    "    return {\"en_ids\": en_ids, \"de_ids\": de_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6318f75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['en', 'de', 'en_tokens', 'de_tokens', 'en_ids', 'de_ids'],\n",
       "    num_rows: 29000\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fn_kwargs = {\"en_vocab\": en_vocab, \"de_vocab\": de_vocab}\n",
    "\n",
    "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85f366b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"torch\"\n",
    "format_columns = [\"en_ids\", \"de_ids\"]\n",
    "\n",
    "train_data = train_data.with_format(type=data_type, columns=format_columns, output_all_columns=True)\n",
    "valid_data = valid_data.with_format(type=data_type, columns=format_columns, output_all_columns=True)\n",
    "test_data = test_data.with_format(type=data_type, columns=format_columns, output_all_columns=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "695247f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_idx):\n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
    "        batch_de_ids = [example[\"de_ids\"] for example in batch]\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_idx)\n",
    "        batch_de_ids = nn.utils.rnn.pad_sequence(batch_de_ids, padding_value=pad_idx)\n",
    "\n",
    "        batch = {\n",
    "            \"en_ids\": batch_en_ids,\n",
    "            \"de_ids\": batch_de_ids\n",
    "        }\n",
    "        return batch\n",
    "    return collate_fn\n",
    "\n",
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3a0ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "pad_index = 0\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a560174",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size_in, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size_in, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, src):\n",
    "        \"\"\"src (L, B)\n",
    "            embeded (L, B, D)\n",
    "            hidden (n_layers * n_directions, B, H)\n",
    "            cell (n_layers * n_directions, B, H)\n",
    "            outputs (L, B, H * n_directions)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        embeded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embeded)\n",
    "\n",
    "        return hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size_out, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.vocab_size_out = vocab_size_out\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding =  nn.Embedding(num_embeddings=vocab_size_out, embedding_dim=embedding_dim)\n",
    "        self.rnn = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, vocab_size_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs, hidden, cell):\n",
    "        \"\"\"inputs (B)\n",
    "           hidden (n_layers * n_directions, B, H)\n",
    "           cell (n_layers * n_direction, B, H)\n",
    "           \"\"\"\n",
    "        \"(B), (1, B)\"\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        \"(1, B, D)\"\n",
    "        embeded = self.dropout(self.embedding(inputs))\n",
    "        \"output: (1, B, hidden)\"\n",
    "        \"hidden: (n_layers * n_directions, B, H)\"\n",
    "        \"cell: (n_layers * n_directions, B, H)\"\n",
    "\n",
    "        output, (hidden, cell) = self.rnn(embeded, (hidden, cell))\n",
    "\n",
    "        \"prediction: (B, vocab_size_out)\"\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder  = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        \"\"\"\n",
    "        src: (L, B)\n",
    "        trg: (L*, B)\n",
    "        \"\"\"\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.vocab_size_out\n",
    "\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        \"\"\"hidden: (n_layers * n_direction, B, L)\n",
    "           cell: (n_layers * n_direction, B, L)\n",
    "           output: (L*, B, vocab_size_out)\n",
    "           \"\"\"\n",
    "\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \"<sos> token (B)\"\n",
    "        inputs = trg[0,:]\n",
    "        for t in range(1, trg_length):\n",
    "            \"output: (B, trg_vocab_size)\"\n",
    "            \"random.random() 0~1\"\n",
    "            output, hidden, cell = self.decoder(inputs, hidden, cell)\n",
    "\n",
    "            outputs[t] = output\n",
    "            teacher_force:bool = random.random() < teacher_forcing_ratio\n",
    "            \"(B, trg_vocab_size) => (B)\"\n",
    "            top1 = output.argmax(dim=1)\n",
    "            inputs = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89807654",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_in = len(de_vocab)\n",
    "vocab_size_out = len(en_vocab)\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder = Encoder(\n",
    "    vocab_size_in=vocab_size_in, embedding_dim=encoder_embedding_dim,\n",
    "    hidden_dim=hidden_dim, n_layers=n_layers, dropout=encoder_dropout\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    vocab_size_out=vocab_size_out, embedding_dim=decoder_embedding_dim,\n",
    "    hidden_dim=hidden_dim, n_layers=n_layers, dropout=decoder_dropout\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f05efd",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96fc60a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "        model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        \"src [L, B]\"\n",
    "        \"trg [L*, B]\"\n",
    "        src = batch['de_ids'].to(device)\n",
    "        trg = batch['en_ids'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \"output: (L*, B, vocab_size_out)\"\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "        output_dim = output.shape[-1]\n",
    "        \"output: ((L*-1) * batch_size, vocab_size_out  )\"\n",
    "        output = output[1:].view(-1, output_dim) #start from <sos>\n",
    "        \"trg ((L*-1) * B)\"\n",
    "        trg = trg[1:].view(-1)\n",
    "        \"output: (N, C, d_1,...,d_k) or (N, C)\"\n",
    "        \"trg: (N, d_1,...,d_k) or (N)\"\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(data_loader)\n",
    "\n",
    "\n",
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        src = batch['de_ids'].to(device)\n",
    "        trg = batch['en_ids'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \"output: (L*, B, vocab_size_out)\"\n",
    "        output = model(src, trg, 0) #turn off teacher forcing\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9665e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:21<03:09, 21.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss:   3.943 | Train PPL:  51.571\n",
      "\tValid loss:   4.255 | Valid PPL:  70.470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:42<02:48, 21.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss:   3.717 | Train PPL:  41.144\n",
      "\tValid loss:   4.166 | Valid PPL:  64.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:03<02:27, 21.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss:   3.540 | Train PPL:  34.479\n",
      "\tValid loss:   3.926 | Valid PPL:  50.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:24<02:06, 21.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss:   3.394 | Train PPL:  29.795\n",
      "\tValid loss:   3.923 | Valid PPL:  50.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:45<01:45, 21.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss:   3.280 | Train PPL:  26.574\n",
      "\tValid loss:   3.926 | Valid PPL:  50.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [02:06<01:24, 21.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss:   3.167 | Train PPL:  23.729\n",
      "\tValid loss:   3.811 | Valid PPL:  45.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:28<01:03, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss:   3.086 | Train PPL:  21.879\n",
      "\tValid loss:   3.794 | Valid PPL:  44.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:48<00:42, 21.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss:   2.978 | Train PPL:  19.642\n",
      "\tValid loss:   3.793 | Valid PPL:  44.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [03:09<00:21, 21.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss:   2.914 | Train PPL:  18.436\n",
      "\tValid loss:   3.743 | Valid PPL:  42.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:30<00:00, 21.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain loss:   2.836 | Train PPL:  17.055\n",
      "\tValid loss:   3.744 | Valid PPL:  42.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "        teacher_forcing_ratio,\n",
    "        device\n",
    "    )\n",
    "\n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        criterion,\n",
    "        device\n",
    "    )\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        torch.save(model.state_dict(), \"tutl-model.pt\")\n",
    "\n",
    "    print(f\"\\tTrain loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "393d59c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.711 | Test PPL:  40.894 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"tutl-model.pt\"))\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b94d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(\n",
    "        sentence: str,\n",
    "        model,\n",
    "        en_nlp,\n",
    "        de_nlp,\n",
    "        en_vocab,\n",
    "        de_vocab,\n",
    "        lower,\n",
    "        sos_token,\n",
    "        eos_token,\n",
    "        device,\n",
    "        max_output_length=25\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = [token.text for token in de_nlp(sentence)]\n",
    "\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        tokens = [sos_token] + tokens + [eos_token]\n",
    "        ids = de_vocab.lookup_indices(tokens)\n",
    "        \"(L) => (L,1)  1 is batch_size\"\n",
    "        tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
    "        hidden, cell = model.encoder(tensor)\n",
    "        inputs = en_vocab.lookup_indices([sos_token])\n",
    "        for _ in range(max_output_length):\n",
    "            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device) #(1)\n",
    "            output, hidden, cell = model.decoder(inputs_tensor, hidden, cell) #output: [1, vocab_size]\n",
    "            predicted_token = output.argmax(-1).item() #(1)\n",
    "            inputs.append(predicted_token)\n",
    "            if predicted_token == en_vocab[eos_token]:\n",
    "                break\n",
    "        tokens = en_vocab.lookup_tokens(inputs)\n",
    "        return tokens\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed660924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.',\n",
       " 'A man in an orange hat starring at something.')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = test_data[0]['de']\n",
    "expected_translation = test_data[0]['en']\n",
    "sentence, expected_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dac772ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', 'a', 'man', 'sitting', 'on', 'a', 'bench', '.', '<eos>']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation = translate_sentence(\n",
    "    sentence=sentence,\n",
    "    model=model,\n",
    "    en_nlp=en_nlp,\n",
    "    de_nlp=de_nlp,\n",
    "    en_vocab=en_vocab,\n",
    "    de_vocab=de_vocab,\n",
    "    lower=True,\n",
    "    sos_token=sos_token,\n",
    "    eos_token=eos_token,\n",
    "    device=device\n",
    ")\n",
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b8a91bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', 'a', 'man', 'sitting', 'on', 'a', 'bench', '.', '<eos>']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Ein Mann sitzt auf einer Bank.\"\n",
    "translation = translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    en_vocab,\n",
    "    de_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    ")\n",
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7c69950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:06<00:00, 161.06it/s]\n"
     ]
    }
   ],
   "source": [
    "translations = [\n",
    "    translate_sentence(\n",
    "        example[\"de\"],\n",
    "        model,\n",
    "        en_nlp,\n",
    "        de_nlp,\n",
    "        en_vocab,\n",
    "        de_vocab,\n",
    "        lower,\n",
    "        sos_token,\n",
    "        eos_token,\n",
    "        device,\n",
    "    )\n",
    "    for example in tqdm(test_data)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fbaa09d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 5.94kB [00:00, 1.99MB/s]\n",
      "Downloading extra modules: 4.07kB [00:00, 2.83MB/s]                   \n",
      "Downloading extra modules: 3.34kB [00:00, 2.99MB/s]\n"
     ]
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b24a36db",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\" \".join(translation[1:-1]) for translation in translations]\n",
    "\n",
    "references = [example[\"en\"] for example in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "060124e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a brown and white dog is running through a field of a large white . .',\n",
       " 'A Boston Terrier is running on lush green grass in front of a white fence.')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1], references[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9353d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer_fn(nlp, lower):\n",
    "    def tokenizer_fn(s):\n",
    "        tokens = [token.text for token in nlp(s)]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        return tokens\n",
    "    return tokenizer_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a0d3f5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['a', 'man', 'wearing', 'a', 'hat', 'hat', 'is', 'his', '.', '.'],\n",
       " ['a', 'man', 'in', 'an', 'orange', 'hat', 'starring', 'at', 'something', '.'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_fn = get_tokenizer_fn(en_nlp, lower)\n",
    "\n",
    "tokenizer_fn(predictions[0]), tokenizer_fn(references[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e41495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bleu.compute(\n",
    "    predictions=predictions, references=references, tokenizer=tokenizer_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ae496f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.16522427300599896,\n",
       " 'precisions': [0.5139862894964936,\n",
       "  0.2273543751603798,\n",
       "  0.11411467589561314,\n",
       "  0.06273862346507068],\n",
       " 'brevity_penalty': 0.9714959966565813,\n",
       " 'length_ratio': 0.9718946239852964,\n",
       " 'translation_length': 12691,\n",
       " 'reference_length': 13058}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
